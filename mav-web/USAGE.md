# MAV Web - Usage Guide

This guide provides step-by-step instructions for using the MAV Web application to visualize the internal workings of language models.

## Getting Started

1. **Access the Application**
   - If deployed, visit the URL provided by Vercel
   - If running locally, visit `http://localhost:3000`

2. **Interface Overview**
   
   The interface consists of:
   - Model configuration form (top section)
   - Visualization panels (bottom section)

## Configuring the Model

1. **Set Your Prompt**
   - Enter the text you want the model to continue generating in the "Prompt" field
   - E.g., "Once upon a time in a distant galaxy"

2. **Select a Model**
   - Choose from the dropdown list:
     - `gpt2`: Smaller, faster model (good for testing)
     - `gpt2-medium`: Medium-sized GPT-2 variant
     - `HuggingFaceTB/SmolLM-135M`: Alternative small language model

3. **Adjust Generation Parameters**
   - **Max Tokens**: Number of tokens to generate (higher values = longer generation time)
   - **Temperature**: Controls randomness (0 = deterministic, higher values = more creative/random)
   - **Top-K**: Limits next-token selection to top K options (lower = more focused)
   - **Top-P**: Uses nucleus sampling (smaller values = more focused)

4. **Click "Start Visualization"**
   - This will initiate the token generation and visualization process
   - You can click "Stop" at any time to halt generation

## Understanding the Visualization Panels

The application displays several panels, each providing a different view into the model's internal state:

### 1. Generated Text Panel

Shows the text being generated by the model, with the most recently generated token highlighted in green.

### 2. Top Predictions Panel

Displays the most likely next tokens according to the model, including:
- Token text
- Probability percentage
- Logit value (raw model output before softmax)

This helps you understand what alternatives the model was considering.

### 3. MLP Activations Panel

Visualizes the activations of the Multi-Layer Perceptron (MLP) layers in the model:
- Each row represents one layer
- Bar length indicates activation strength
- Color indicates sign (positive/negative)
- Numerical value shows precise activation level

### 4. Attention Entropy Panel

Shows the entropy of attention distributions across model layers:
- Higher values indicate more diffuse attention (model attending to many tokens)
- Lower values indicate focused attention (model attending to specific tokens)
- Helps understand how the model is processing context

### 5. Output Distribution Panel

Displays the probability distribution across all possible output tokens:
- Shows the overall shape of the probability mass
- Helps visualize model uncertainty
- Provides insight into token selection dynamics

## Tips for Effective Use

1. **Start Simple**
   - Begin with short prompts and small models
   - Use temperature = 0 initially to see deterministic outputs

2. **Observe Token-by-Token**
   - Watch how each generated token affects the model's internal state
   - Notice patterns in activations as specific words or phrases are generated

3. **Experiment with Parameters**
   - Try different temperature settings to see how randomness affects internal states
   - Adjust top-k and top-p to see how constraining token selection changes the model behavior

4. **Compare Models**
   - Try different models on the same prompt to compare their internal behaviors
   - Note differences in attention patterns and MLP activations

5. **Performance Considerations**
   - Larger models will load more slowly
   - Longer generation runs may strain browser resources
   - If the application becomes unresponsive, refresh the page and try with fewer tokens

## Troubleshooting

- **Slow Response Time**: Try a smaller model or reduce max tokens
- **Error Messages**: Check that the selected model is available and the parameters are valid
- **Visualization Not Updating**: Ensure your browser supports EventSource/SSE
- **Connection Errors**: The serverless function may have timed out; refresh and try again 